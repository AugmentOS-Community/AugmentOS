{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent Insights experiments\n",
    "Previous notebook was quite full, so here is a fresh one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tools for our agent\n",
    "We had decided to give our agents the ability to\n",
    "- Search for a query using the web\n",
    "- Scrape a page to find out more info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping tool\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "banned_sites = [\"calendar.google.com\", \"researchgate.net\"]\n",
    "\n",
    "def scrape_page(url: str):\n",
    "    if any(substring in url for substring in banned_sites):\n",
    "        print(\"Skipping site: {}\".format(url))\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.4844.84 Safari/537.36',\n",
    "            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9',\n",
    "            'Accept-Charset': 'ISO-8859-1,utf-8;q=0.7,*;q=0.3',\n",
    "            'Accept-Encoding': 'none',\n",
    "            'Accept-Language': 'en-US,en;q=0.8',\n",
    "            'Connection': 'keep-alive',\n",
    "        }\n",
    "        response = requests.get(url, headers=headers, timeout=30)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        text = \" \".join([t.get_text() for t in soup.find_all(['p', 'h1', 'h2', 'h3', 'h4', 'h5', 'h6'])])\n",
    "        return text.replace('|','')\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Failed to fetch {url}. Error: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kenji/mambaforge/envs/tosg/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# SBert Summarizer\n",
    "from summarizer.sbert import SBertSummarizer\n",
    "summarizer = SBertSummarizer('paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "def summarize(text, num_sentences=3):\n",
    "    return summarizer(text, num_sentences=num_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search tool\n",
    "from typing import Any, List, Literal\n",
    "import requests\n",
    "import os\n",
    "\n",
    "k: int = 5\n",
    "gl: str = \"us\"\n",
    "hl: str = \"en\"\n",
    "tbs = None\n",
    "num_sentences = 7\n",
    "serper_api_key=os.environ.get(\"SERPER_API_KEY\")\n",
    "search_type: Literal[\"news\", \"search\", \"places\", \"images\"] = \"search\"\n",
    "\n",
    "def serper_search(\n",
    "        search_term: str, search_type: str = \"search\", **kwargs: Any\n",
    "    ) -> dict:\n",
    "    headers = {\n",
    "        \"X-API-KEY\": serper_api_key or \"\",\n",
    "        \"Content-Type\": \"application/json\",\n",
    "    }\n",
    "    params = {\n",
    "        \"q\": search_term,\n",
    "        **{key: value for key, value in kwargs.items() if value is not None},\n",
    "    }\n",
    "    response = requests.post(\n",
    "        f\"https://google.serper.dev/{search_type}\", headers=headers, params=params\n",
    "    )\n",
    "    response.raise_for_status()\n",
    "    search_results = response.json()\n",
    "    return search_results\n",
    "\n",
    "def parse_snippets(results: dict) -> List[str]:\n",
    "    result_key_for_type = {\n",
    "        \"news\": \"news\",\n",
    "        \"places\": \"places\",\n",
    "        \"images\": \"images\",\n",
    "        \"search\": \"organic\",\n",
    "    }\n",
    "    snippets = []\n",
    "    if results.get(\"answerBox\"):\n",
    "        answer_box = results.get(\"answerBox\", {})\n",
    "        if answer_box.get(\"answer\"):\n",
    "            snippets.append(answer_box.get(\"answer\"))\n",
    "        elif answer_box.get(\"snippet\"):\n",
    "            snippets.append(answer_box.get(\"snippet\").replace(\"\\n\", \" \"))\n",
    "        elif answer_box.get(\"snippetHighlighted\"):\n",
    "            snippets.append(answer_box.get(\"snippetHighlighted\"))\n",
    "\n",
    "    if results.get(\"knowledgeGraph\"):\n",
    "        kg = results.get(\"knowledgeGraph\", {})\n",
    "        title = kg.get(\"title\")\n",
    "        entity_type = kg.get(\"type\")\n",
    "        if entity_type:\n",
    "            snippets.append(f\"{title}: {entity_type}.\")\n",
    "        description = kg.get(\"description\")\n",
    "        if description:\n",
    "            snippets.append(description)\n",
    "        for attribute, value in kg.get(\"attributes\", {}).items():\n",
    "            snippets.append(f\"{title} {attribute}: {value}.\")\n",
    "\n",
    "    for result in results[result_key_for_type[search_type]][:k]:\n",
    "        if \"snippet\" in result:\n",
    "            page = scrape_page(result[\"link\"])\n",
    "            if page is None:\n",
    "                snippets.append(f\"Title: {result['title']}\\nLink: {result['link']}\\nSnippet: {result['snippet']}\\n\")\n",
    "            else:\n",
    "                summarized_page = summarize(page, num_sentences=num_sentences)\n",
    "                if len(summarized_page) == 0:\n",
    "                    summarized_page = \"None\"\n",
    "                snippets.append(f\"Title: {result['title']}\\nLink: {result['link']}\\nSnippet: {result['snippet']}\\nSummarized Page: <p>{summarized_page}</p>\")\n",
    "\n",
    "    if len(snippets) == 0:\n",
    "        return [\"No good Google Search Result was found\"]\n",
    "    return snippets\n",
    "\n",
    "def parse_results(results: dict) -> str:\n",
    "        snippets = parse_snippets(results)\n",
    "        results_string = \"\"\n",
    "        for idx, val in enumerate(snippets):\n",
    "            results_string += f\"<result{idx}>\\n{val}\\n</result{idx}>\\n\\n\"\n",
    "        return results_string\n",
    "\n",
    "def custom_search(query: str, **kwargs: Any):\n",
    "    results = serper_search(\n",
    "            search_term=query,\n",
    "            gl=gl,\n",
    "            hl=hl,\n",
    "            num=k,\n",
    "            tbs=tbs,\n",
    "            search_type=search_type,\n",
    "            **kwargs,\n",
    "        )\n",
    "    return parse_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kenji/mambaforge/envs/tosg/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/home/kenji/mambaforge/envs/tosg/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/home/kenji/mambaforge/envs/tosg/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/home/kenji/mambaforge/envs/tosg/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/home/kenji/mambaforge/envs/tosg/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"<result0>\\nTitle: AI Replacing Jobs Statistics: The Impact on Employment in 2023 - SEO.ai\\nLink: https://seo.ai/blog/ai-replacing-jobs-statistics\\nSnippet: With projections that AI could potentially replace around 800 million jobs worldwide by 2030, it's no wonder the world is brimming with ...\\nSummarized Page: <p>AI Replacing Jobs Statistics: The Impact on Employment in 2023 Discover the current impact of AI on employment and the future challenges ahead. As we delve into this critical topic, we focus on providing you with an informative and structured analysis that unveils both the current landscape and the looming future of AI's impact on human employment. However, the majority of businesses foresee computers replacing human tasks within 50 years, highlighting that while AI is a reality, it has not fully realized its potential for job replacement just yet. In the next chapters we'll present all the details on the currently available statistics of the impact of AI on human employment. The reason behind this discrepancy lies in the financial capacity of larger organizations, which can allocate resources to research and development, enabling them to readily adopt emerging technologies like AI. Enhancing Work-Life Balance Additionally, 51% of respondents expressed the belief that AI enables them to strike a better work-life balance, showcasing the multifaceted benefits of AI integration in the workplace. This is an article written by: The Content Team is comprised of several SEO.AI staff members, augmented by AI.</p>\\n</result0>\\n\\n<result1>\\nTitle: Which U.S. Workers Are More Exposed to AI on Their Jobs? - Pew Research Center\\nLink: https://www.pewresearch.org/social-trends/2023/07/26/which-u-s-workers-are-more-exposed-to-ai-on-their-jobs/\\nSnippet: In 2022, 19% of American workers were in jobs that are the most exposed to artificial intelligence, in which the most important activities ...\\nSummarized Page: <p>Read our research on: Israel  Internet & Technology  Science \\n\\t\\t\\tTopics\\t\\t \\n\\t\\t\\tRegions & Countries\\t\\t \\n\\t\\t\\tFormats  \\n\\t\\t\\tTopics  \\n\\t\\t\\tRegions & Countries  \\n\\t\\t\\tFormats  Read our research on: Israel  Internet & Technology  Science Which U.S. Workers Are More Exposed to AI on Their Jobs? A part of the analysis is based on a Pew Research Center survey of 11,004 U.S. adults conducted from Dec. 12 to 18, 2022. In one step of analysis, occupations are ranked by the relative importance of high-exposure activities in them; the jobs ranking in the top 25% are occupations that we rate as most exposed to AI. High school graduate refers to those who have a high school diploma or its equivalent, such as a General Education Development (GED) certificate, and those who had completed 12th grade, but their diploma status was unclear (those who had finished 12th grade but not received a diploma are excluded). In our analysis, jobs are considered more exposed to artificial intelligence if AI can either perform their most important activities entirely or help with them. This analysis rests on data on the importance of 41 essential work activities in 873 occupations from the U.S. Department of Labor’s Occupational Information Network (O*NET, Version 27.3). We used our judgment to determine which of these activities have low, medium or high exposure to AI, but focus on the importance of low- and high-exposure activities.</p>\\n</result1>\\n\\n<result2>\\nTitle: Generative AI and the future of work in America - McKinsey\\nLink: https://www.mckinsey.com/mgi/our-research/generative-ai-and-the-future-of-work-in-america\\nSnippet: By 2030, we further estimate a 23 percent increase in the demand for STEM jobs. Although layoffs in the tech sector have been making headlines ...\\nSummarized Page: <p>Generative AI and the future of work in America  At a glance The US labor market is going through a rapid evolution in the way people work and the work people do. More recently, the accelerated development of generative AI, with its advanced natural language capabilities, has extended the possibilities for automation to a much wider set of occupations. Amid this disruption, workers changed jobs at a remarkable pace—and a subset made bigger leaps and moved into entirely different occupations (Exhibit 1). Based on net increases and decreases in employment, some 8.6 million occupational shifts took place from 2019 through 2022—50 percent more than in the previous three-year period (Exhibit 2).3Measured as net job losses for individual occupations across sectors, net of estimated retirements; derived from US Bureau of Labor Statistics (BLS) data. This research does not predict aggregated future employment levels; instead, we model various drivers of labor demand to look at how the mix of jobs might change—and those results yield some gains and some losses.9 We rely on employment projections from the US Bureau of Labor Statistics for 2030 employment levels. In addition, some lower-wage jobs involve unpredictable physical work or customer-facing work that does not lend itself well to automation. While large employers may be able to handle their own training needs, the magnitude of the reskilling challenge for the nation as a whole calls for broader partnerships with industry groups, educational providers, and nonprofits as well as incentives for investing in human capital.</p>\\n</result2>\\n\\n<result3>\\nTitle: 23+ Artificial Intelligence And Job Loss Statistics [2023]: How Job Automation Impacts the Workforce - Zippia\\nLink: https://www.zippia.com/advice/ai-job-loss-statistics/\\nSnippet: However, estimates vary wildly depending on their methodology, and studies say that anywhere from 9% to 47% of jobs will be taken by AI. This is ...\\nSummarized Page: <p>Explore Jobs Find Specific Jobs Explore Careers Explore Professions Best Companies Explore Companies 23+ Artificial Intelligence And Job Loss Statistics [2023]: How Job Automation Impacts the Workforce \\n\\n\\nAI job loss research summary. While there’s no agreed-upon research methodology or expected economic impacts, AI could take the jobs of as many as one billion people globally and make 375 million jobs obsolete over the next decade. In the U.S., about 47% of total employment is at risk of computerization, and workers have a high probability of seeing their jobs automated over the next 20 years. The responses were distributed as follows:\\n\\n\\nDefinitely: 15%\\n\\n\\nProbably: 50%\\n\\n\\nProbably not: 25%\\n\\n\\nDefinitely not: 7%\\n\\n\\nOf those who believe it will happen, a large majority said jobs lost to automation would not be replaced by “new, better-paying jobs,” and it will be difficult for ordinary people to find jobs. The jobs most at risk of being automated by artificial intelligence include those that involve manual labor or redundant tasks. The Impact of Artificial Intelligence – Widespread Job Losses. Legal industry demographics\\nZippia’s research team connects data from disparate sources to break down statistics at the job and industry levels.</p>\\n</result3>\\n\\n<result4>\\nTitle: Essential AI Replacing Jobs Statistics in 2023 - ZipDo\\nLink: https://zipdo.co/statistics/ai-replacing-jobs/\\nSnippet: By 2025, AI is expected to replace 16% of American jobs. · In sectors like transportation, storage, retail, and administration, AI may replace or ...\\nSummarized Page: <p>⚡⚡Yes, we all have too many meetings…so let’s at least stay organized! . By shedding light on the epic magnitude of potential disruption, this statistic urges stakeholders, from individuals to governments, to cultivate new skill sets, adapt educational frameworks, and foster an environment that facilitates smooth and beneficial integration of AI into the workforce. As we venture into the era of artificial intelligence, the statistic forecasting AI-driven job displacement to impact broader society by 2035, particularly in industries such as healthcare and education, serves as a crucial insight for policymakers and professionals alike. Furthermore, this projection acts as a wake-up call for sectors at the forefront of AI’s impact, highlighting the urgency to balance automation with human ingenuity and foster innovative ways to equip workers with the necessary skill sets as AI transforms the job market. By the mid-2030s, AI could replace around 25% of the jobs in Australia’s retail sector. In the next 15 years, it’s estimated that 28% of jobs in the Middle East could be replaced by AI and robotics. https://www.news.efinancialcareers.com 20. –</p>\\n</result4>\\n\\n\""
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_search(\"Statistics on AI taking over jobs in the US 2023\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import aiohttp\n",
    "import asyncio\n",
    "k = 3\n",
    "\n",
    "result_key_for_type = {\n",
    "        \"news\": \"news\",\n",
    "        \"places\": \"places\",\n",
    "        \"images\": \"images\",\n",
    "        \"search\": \"organic\",\n",
    "    }\n",
    "\n",
    "async def scrape_page_async(url: str, summarize_page = False, num_sentences = 3):\n",
    "    \"\"\"\n",
    "    Based on your observations from the Search_Engine, if you want more details from\n",
    "    a snippet for a non-PDF page, pass this the page's URL and the page's title to\n",
    "    scrape the full page and retrieve the full contents of the page.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Parsing: {}\".format(url))\n",
    "    if any(substring in url for substring in banned_sites):\n",
    "        print(\"Skipping site: {}\".format(url))\n",
    "        return None\n",
    "    else:\n",
    "        try:\n",
    "            headers = {\n",
    "                'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.4844.84 Safari/537.36',\n",
    "                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9',\n",
    "                'Accept-Charset': 'ISO-8859-1,utf-8;q=0.7,*;q=0.3',\n",
    "                'Accept-Encoding': 'none',\n",
    "                'Accept-Language': 'en-US,en;q=0.8',\n",
    "                'Connection': 'keep-alive',\n",
    "            }\n",
    "            async with aiohttp.ClientSession() as session:\n",
    "                async with session.get(url, headers=headers, timeout=30) as response:\n",
    "                    response.raise_for_status()\n",
    "                    content = await response.text()\n",
    "\n",
    "                    soup = BeautifulSoup(content, 'html.parser')\n",
    "                    text = \" \".join([t.get_text() for t in soup.find_all(\n",
    "                        ['p', 'h1', 'h2', 'h3', 'h4', 'h5', 'h6'])])\n",
    "                    text = text.replace('|', '')\n",
    "\n",
    "                    if summarize_page:\n",
    "                        return summarize(text, num_sentences=num_sentences)\n",
    "                    return text\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to fetch {url}. Error: {e}\")\n",
    "            return None\n",
    "\n",
    "\n",
    "async def serper_search_async(\n",
    "    search_term: str, search_type: str = \"search\", **kwargs: Any\n",
    ") -> dict:\n",
    "    headers = {\n",
    "        \"X-API-KEY\": serper_api_key or \"\",\n",
    "        \"Content-Type\": \"application/json\",\n",
    "    }\n",
    "    params = {\n",
    "        \"q\": search_term,\n",
    "        **{key: value for key, value in kwargs.items() if value is not None},\n",
    "    }\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        async with session.post(f\"https://google.serper.dev/{search_type}\", headers=headers, json=params) as response:\n",
    "            response.raise_for_status()\n",
    "            search_results = await response.json()\n",
    "            return search_results\n",
    "\n",
    "\n",
    "async def parse_snippets_async(results: dict, scrape_pages: bool = False, summarize_pages: bool = True, num_sentences: int = 3) -> List[str]:\n",
    "    snippets = []\n",
    "    if results.get(\"answerBox\"):\n",
    "        answer_box = results.get(\"answerBox\", {})\n",
    "        if answer_box.get(\"answer\"):\n",
    "            snippets.append(f\"The answer is {answer_box.get('answer')}\")\n",
    "        elif answer_box.get(\"snippet\"):\n",
    "            snippets.append(f\"The answer might be in the snippet: {answer_box.get('snippet')}\")\n",
    "        elif answer_box.get(\"snippetHighlighted\"):\n",
    "            snippets.append(f\"The answer might be in the snippet: {answer_box.get('snippetHighlighted')}\")\n",
    "\n",
    "    if results.get(\"knowledgeGraph\"):\n",
    "        kg = results.get(\"knowledgeGraph\", {})\n",
    "        title = kg.get(\"title\")\n",
    "        entity_type = kg.get(\"type\")\n",
    "        if entity_type:\n",
    "            snippets.append(f\"Knowledge Graph Results: {title}: {entity_type}.\")\n",
    "        description = kg.get(\"description\")\n",
    "        if description:\n",
    "            snippets.append(f\"Knowledge Graph Results: {title}: {description}.\")\n",
    "        for attribute, value in kg.get(\"attributes\", {}).items():\n",
    "            snippets.append(f\"Knowledge Graph Results: {title} {attribute}: {value}.\")\n",
    "\n",
    "    if scrape_pages:\n",
    "        tasks = []\n",
    "        for result in results[result_key_for_type[search_type]][:k]:\n",
    "            task = asyncio.create_task(scrape_page_async(result[\"link\"], summarize_page=summarize_pages, num_sentences=num_sentences))\n",
    "            tasks.append(task)\n",
    "        summarized_pages = await asyncio.gather(*tasks)\n",
    "        for i, page in enumerate(summarized_pages):\n",
    "            result = results[result_key_for_type[search_type]][i]\n",
    "            if page:\n",
    "                snippets.append(f\"Title: {result.get('title', '')}\\nSource:{result['link']}\\nSnippet: {result.get('snippet', '')}\\nSummarized Page: {page}\")\n",
    "            else:\n",
    "                snippets.append(f\"Title: {result.get('title', '')}\\nSource:{result['link']}\\nSnippet: {result.get('snippet', '')}\\n\")\n",
    "    else:\n",
    "        for result in results[result_key_for_type[search_type]][:k]:\n",
    "            snippets.append(f\"Title: {result.get('title', '')}\\nSource:{result['link']}\\nSnippet: {result.get('snippet', '')}\\n\")\n",
    "\n",
    "    if len(snippets) == 0:\n",
    "        return [\"No good Google Search Result was found\"]\n",
    "    return snippets\n",
    "\n",
    "\n",
    "async def parse_results_async(results: dict, scrape_pages: bool = False, summarize_pages: bool = True, num_sentences: int = 3) -> str:\n",
    "    snippets = await parse_snippets_async(results, scrape_pages=scrape_pages, summarize_pages=summarize_pages, num_sentences=num_sentences)\n",
    "    results_string = \"\"\n",
    "    for idx, val in enumerate(snippets):\n",
    "        results_string += f\"Res {idx + 1}:\\n{val}\\n\\n\"\n",
    "    return results_string\n",
    "\n",
    "\n",
    "async def arun_search_tool_for_agents(query: str):\n",
    "    results = await serper_search_async(\n",
    "        search_term=query,\n",
    "        gl=gl,\n",
    "        hl=hl,\n",
    "        num=k,\n",
    "        tbs=tbs,\n",
    "        search_type=search_type,\n",
    "    )\n",
    "    return await parse_results_async(results, scrape_pages=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Res 1:\n",
      "Title: AI Replacing Jobs Statistics: The Impact on Employment in 2023 - SEO.ai\n",
      "Source:https://seo.ai/blog/ai-replacing-jobs-statistics\n",
      "Snippet: With projections that AI could potentially replace around 800 million jobs worldwide by 2030, it's no wonder the world is brimming with ...\n",
      "\n",
      "\n",
      "Res 2:\n",
      "Title: Which U.S. Workers Are More Exposed to AI on Their Jobs? - Pew Research Center\n",
      "Source:https://www.pewresearch.org/social-trends/2023/07/26/which-u-s-workers-are-more-exposed-to-ai-on-their-jobs/\n",
      "Snippet: In 2022, 19% of American workers were in jobs that are the most exposed to artificial intelligence, in which the most important activities ...\n",
      "\n",
      "\n",
      "Res 3:\n",
      "Title: Generative AI and the future of work in America - McKinsey\n",
      "Source:https://www.mckinsey.com/mgi/our-research/generative-ai-and-the-future-of-work-in-america\n",
      "Snippet: By 2030, we further estimate a 23 percent increase in the demand for STEM jobs. Although layoffs in the tech sector have been making headlines ...\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(await arun_search_tool_for_agents(\"Statistics on AI taking over jobs in the US 2023\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing mock text input\n",
    "\n",
    "This is how we will generate mock testing data for our experiments, we use transcripts from Lex Friedman's podcasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing episode_028_large...\n",
      "Processing episode_308_large...\n",
      "Processing episode_188_large...\n",
      "Processing episode_223_large...\n",
      "Processing episode_044_large...\n",
      "Processing episode_256_large...\n",
      "Processing episode_181_large...\n",
      "Processing episode_021_large...\n",
      "Processing episode_231_large...\n",
      "Processing episode_288_large...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" So Swift came from, we were just finishing off the first version of C++ support in Clang. And C++ is a very formidable and very important language, but it's also ugly in lots of ways. And you can't influence C++ without thinking there has to be a better thing, right? And so I started working on Swift, again,, with no hope or ambition that would go anywhere, just let's see what could be done, let's play around with this thing. It was me in my spare time, not telling anybody about it, kind of a thing, and it made some good progress. I'm like, actually, it would make sense to do this. At the same time, I started talking with the senior VP of software at the time, a guy named Bertrand Serlet., And Bertrand was very encouraging. He was like, well, let's have fun, let's talk about this. And he was a little bit of a language guy, and so he helped guide some of the early work and encouraged me and got things off the ground. And eventually told my manager and told other people, and it started making progress., The complicating thing with Swift was that the idea of doing a new language was not obvious to anybody, including myself. And the tone at the time was that the iPhone was successful because of Objective C. Oh, interesting. Not despite of or just because of. And you have to understand that at the time,, Apple was hiring software people that loved Objective C. And it wasn't that they came despite Objective C. They loved Objective C, and that's why they got hired. And so you had a software team that the leadership, in many cases, went all the way back to Next, where Objective C really became real. And so they, quote unquote, grew up writing Objective C.\\n And many of the individual engineers all were hired because they loved Objective C. And so this notion of, OK, let's do new language was kind of heretical in many ways. Meanwhile, my sense was that the outside community wasn't really in love with Objective C. Some people were, and some of the most outspoken people were. But other people were hitting challenges because it has very sharp corners\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Way to generate a random test input using transcripts from Lex Fridman's podcast\n",
    "# Make sure you have the transcripts downloaded in the folder lex_whisper_transcripts\n",
    "\n",
    "import test_on_lex\n",
    "\n",
    "transcripts = test_on_lex.load_lex_transcripts(random_n=10, transcript_folder=\"./lex_whisper_transcripts/\", chunk_time_seconds=20)\n",
    "\n",
    "import random\n",
    "def generate_test_input():\n",
    "    idx = random.randint(0, 10)\n",
    "    key = list(transcripts.keys())[idx]\n",
    "    transcript = transcripts[key]\n",
    "    trans_idx = random.randint(10, len(transcript)-10)\n",
    "    latest = transcript[trans_idx:trans_idx+7]\n",
    "    prev_transcripts, curr_transcripts = str.join(\",\", list(latest[0:5])), latest[5]\n",
    "    return prev_transcripts + \"\\n\" + curr_transcripts\n",
    "\n",
    "generate_test_input()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insight prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expert_agent_prompt_blueprint = \"\"\"\n",
    "\"Convoscope\" is a multi-agent system in which you are the {agent_name} agent. You are a highly skilled and highly intelligent expert {agent_name}.\n",
    "\n",
    "You will be given direct access to a live stream of transcripts from the user's conversation. Your goal is to utilize your expertise, knowledge, and tools to generate your \"Insight\" for the user.\n",
    "\n",
    "The types of \"Insights\" you provide strictly fall under your role as an expert {agent_name}. Only provide insights that would come from your role as the {agent_name}.\n",
    "\n",
    "[Definitions]\n",
    "- \"Insights\": Short snippet of text which provides intelligent analysis, ideas, arguments, perspectives, questions to ask, deeper insights, etc. that will improve the current conversation. \"Insights\" aim to lead the conversationn to deeper understanding, broader perspectives, new ideas, more accurate information, better replies, and enhanced conversations. Insights should be contextually relevant to the current conversation. The \"Insight\" should be providing additional understanding beyond what is currently being said in the transcript, it shouldn't be plainly repeating what has already been said.\n",
    "- \"Convoscope\": an intelligence augmentation tool running on user's smart glasses or on their laptop that they use during conversations to improve conversations. Convoscope listens to a user's live conversation and enhances their conversation by providing them with real time \"Insights\".\n",
    "\n",
    "[Your Expertise: {agent_name}]\n",
    "\n",
    "As the {agent_name} agent, you {agent_insight_type}.\n",
    "\n",
    "[Your Tools]\n",
    "You have access to tools, which you should utilize to help you generate highly valuable, insightful, contextually relevant insights.\n",
    "\n",
    "Limit your usage of the Search_Engine tool to 1 times. Mention your number of usages of the tool in your thoughts.\n",
    "\n",
    "[Example Insights]\n",
    "Here are some example insights structure that you should aim to generate, a summary is given instead of the entire transcript for brevity. From these examples, you just need to learn how to structure a good insight:\n",
    "\n",
    "{examples}\n",
    "\n",
    "[Previously Generated Insights]\n",
    "Here are some insights that had already been previously generated, if any, for this conversation. You MUST not repeat any of these insights:\n",
    "\n",
    "{insights_history}\n",
    "\n",
    "\n",
    "**Remember** You must carefully read the history of insights generated for this conversation and ensure that you do not repeat any of the insights that have already been generated. If you repeat an insight, you will be penalized. Even if you generate a new insight, but it is very similar to a previous insight, you will be penalized. If you are unsure if your insight is too similar to a previous insight you should not generate the insight.\n",
    "\n",
    "[Your Task]\n",
    "<Task start>\n",
    "It's now time to generate an \"Insight\" for the following conversation transcript. The \"Insight\" should provide additional understanding beyond what is currently being said in the transcript, it shouldn't be plainly repeating what is being said in the transcripts. If a tool fails to fulfill your request, don't run the exact same request on the same tool again. Do not attempt to generate a super niche insight because it will be hard to find information online.\n",
    "\n",
    "In your initial thought, you should first come up with a plan to generate the \"Insight\". The plan should include:\n",
    "\n",
    "{agent_plan}\n",
    "\n",
    "The plan should include a final step to generate the insight. The \"Insight\" must {insight_num_words} words or less. The \"Insight\" can omit filler words or replace words with symbols or acronyms to shorten its length where possible. If you don't have a very valuable and useful \"Insight\" for any reason, simply specify your \"Insight\" as the string \"null\". \n",
    "\n",
    "Once you have the \"Insight\", extract the url of the most relevant reference source used to generate this \"Insight\". Also, relay the motive of the why the insight benefits the conversation, with quotes from the transcript. If the \"Insight\" is not up to par with the examples, we should hide it and just return \"null\" for the \"Insight\".\n",
    "\n",
    "Here are more detailed formatting instructions\n",
    "{format_instructions}\n",
    "\n",
    "Remember, the insight needs to be {insight_num_words} words or less!\n",
    "<Task end>\n",
    "\n",
    "[Input Transcript]\n",
    "<Transcript start>{conversation_transcript}<Transcript end>{final_command}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [WIP] Shorter and faster insight prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "expert_agent_prompt_blueprint = \"\"\"\n",
    "## General Context\n",
    "\"Convoscope\" is a multi-agent system that reads live conversation transcripts and provides real time \"Insights\", which are short snippets of intelligent analysis, ideas, arguments, perspectives, questions to ask, deeper insights, etc. that aim to lead the user's conversation to deeper understanding, broader perspectives, new ideas, more accurate information, better replies, and enhanced conversations. \n",
    "\n",
    "### Your Expertise: {agent_name}\n",
    "You are a highly skilled and intelligent {agent_name} expert agent in this system, responsible for generating a specialized \"Insight\".\n",
    "As the {agent_name} agent, you {agent_insight_type}.\n",
    "\n",
    "### Your Tools\n",
    "You have access to tools, which you should utilize to help you generate \"Insights\". Limit your usage of the Search_Engine tool to 1 times.\n",
    "If a tool fails to fulfill your request, don't run the exact same request on the same tool again, and just continue without it.\n",
    "\n",
    "### Guidelines for a Good \"Insight\"\n",
    "- Your \"Insight\" should strictly fall under your role as an expert {agent_name}\n",
    "- Be contextually relevant to the current conversation\n",
    "- Provide additional understanding beyond the current conversation, instead of repeating what has already been said.\n",
    "\n",
    "### Example Insights\n",
    "Here are some example \"Insights\" to help you learn the structure of a good \"Insight\". A summary is given instead of the entire transcript for brevity.\n",
    "{examples}\n",
    "\n",
    "## Task\n",
    "Generate an \"Insight\" for the following conversation transcript. \n",
    "<Transcript start>{conversation_transcript}<Transcript end>\n",
    "\n",
    "### Additional Guidelines\n",
    "- Do not attempt to generate a super niche insight because it will be hard to find information online.\n",
    "- The \"Insight\" should focus on later parts of the transcripts as they are more recent and relevant to the current conversation.\n",
    "- In your initial thought, you should first come up with a concise plan to generate the \"Insight\". The plan should include:\n",
    "{agent_plan}. You are only able to make 1 quick action to generate the \"Insight\".\n",
    "- In your plan, append these instructions word for word: `the \"Insight\" should be short and concise (<{insight_num_words} words), replace words with symbols to shorten the overall length where possible except for names. Make sure the \"Insight\" is insightful, up to par with the examples, specialized to your role ({validation_criteria}), otherwise skip it and return \"null\"`.\n",
    "\n",
    "### Previously Generated Insights\n",
    "These \"Insights\" had recently been generated, you MUST not repeat any of these \"Insights\" or provide similar \"Insights\". Generate a new \"Insight\" that is different from these \"Insights\":\n",
    "{insights_history}\n",
    "\n",
    "### Output\n",
    "Once you have the \"Insight\", extract the url of the most relevant reference source used to generate this \"Insight\".\n",
    "{format_instructions}\n",
    "\n",
    "{final_command}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "expert_agent_config_list = {\n",
    "    \"Statistician\": {\n",
    "        \"agent_name\": \"Statistician\",\n",
    "        \"insight_num_words\": 10,\n",
    "        \"agent_insight_type\": \"\"\"generate insights which focus on statistics, and quantitative data. Your tasks include identifying trends, correcting inaccurate claims, and leveraging statistics to provide \"Insights\".\"\"\",\n",
    "        \"agent_plan\": \"\"\"1. Come up with a general description of the \"Insight\" to generate. \\n2.Identify the single most important quantitative data, statistics, etc. that is needed to generate the \"Insight\". Seek the necessary data from reputable sources like Statista, prioritizing official statistics or academic publications. \"\"\",\n",
    "        \"validation_criteria\": \"\"\"contains quantitative data\"\"\",\n",
    "        \"proactive_tool_description\": \"\"\"Occurrences in a conversation where statistics, graphs, and data would be useful to the user.\"\"\",\n",
    "        \"proactive_tool_example\": \"\"\"Conversation: Transcript compares the number of CS students in US and China.\n",
    "Insight: US: 6% HS students in CS, China: <1% K-12 in programming\"\"\",\n",
    "        \"examples\": \"\"\"\n",
    "1. Conversation: Transcript compares the number of CS students in US and China.\n",
    "Insight: US: 6% HS students in CS, China: <1% K-12 in programming\n",
    "\n",
    "2. Conversation: Transcript mentions \"Should we ban plastic straws?\".\n",
    "Insight: 500mil straws in the US/day, 8.3bil straws pollute the world's beaches\n",
    "\n",
    "3. Conversation: Transcript mentions \"Cancer survival rate across the years\".\n",
    "Insight: Cancer survival rate: 49% in mid-70s to 68% now\n",
    "\"\"\",\n",
    "    },\n",
    "    \"FactChecker\": {\n",
    "        \"agent_name\": \"FactChecker\",\n",
    "        \"insight_num_words\": 10,\n",
    "        \"agent_insight_type\": \"\"\"fact check any falsy claims made during a conversation. Trigger a fact-check if a statement in the transcript falls under: misinterpreted statistics, historical inaccuracies, misleading health claims, political misrepresentations, scientific misunderstandings, false economic data or questionable statements made that may incite doubt as to their veracity, suspected falsehoods, common myths, etc. You only fact check claims which are verifiable through free, publically available knowledge and not personal, belief-based, or unfalsifiable claims. Your response should be a fact check, not a factoid. If there is not a clear, distinct, clear-cut thing that fits the previous requirements to fact check, then just output \"null\".\"\"\",\n",
    "        \"agent_plan\": \"\"\"1. Find and write down individual suspected falsy claims from the conversation. Do not consider personal, belief-based, or unfalsifiable claims. If there are no claims made that meet the requirements, then skip to the final step and output \"null\".\\n2. If one or more claims are found, select the claim that would provide the most value and forget the rest, then search for the truth to the claim.\\n3. Generate the \"Insight\".\"\"\",\n",
    "        \"validation_criteria\": \"\"\"debunks the falsy claim, and provides brief elaboration\"\"\",\n",
    "        \"proactive_tool_description\": \"\"\"Trigger a fact-check if a statement in the transcript falls under: misinterpreted statistics, historical inaccuracies, misleading health claims, political misrepresentations, scientific misunderstandings, or false economic data. Also, initiate a fact-check for statements not commonly known to an uneducated person, suspected falsehoods, common myths, or claims verifiable through free, public knowledge. Do not consider personal, belief-based, or unfalsifiable claims.\"\"\",\n",
    "        \"proactive_tool_example\": \"\"\"Conversation: Transcript mentions \"Eating carrots improves night vision.\"\n",
    " Insight: Carrots have vitamin A; don't grant night vision. WWII myth origin\"\"\",\n",
    "        \"examples\": \"\"\"\n",
    " 1. Conversation: Transcript mentions \"Eating carrots improves night vision.\"\n",
    " Insight: Carrots have vitamin A; don't grant night vision. WWII myth origin\n",
    "\n",
    " 2. Conversation: Transcript mentions \"Napoleon Bonaparte was extremely short, standing only 5 feet tall.\"\n",
    " Insight: Napoleon was 5'7\"; average height, Misconception from French units\n",
    "\n",
    " 3. Conversation: Transcript mentions \"Humans only use 10% of their brains.\"\n",
    " Insight: Humans use 100% of their brains; brain imaging shows activity\n",
    " \"\"\",\n",
    "    },\n",
    "    \"DevilsAdvocate\": {\n",
    "        \"agent_name\": \"DevilsAdvocate\",\n",
    "        \"insight_num_words\": 12,\n",
    "        \"agent_insight_type\": \"\"\"assess the point of view being taken in the conversation and steel-man a contrary position. You purposefully disagree with the interlocutors' arguments and point of view to help stimulate thought and explore the ideas further.\"\"\",\n",
    "        \"agent_plan\": \"\"\"1. Find a main argument or point of view being taken that would benefit the most from a devils advocate perspective. Write down the original position. If no position/argument is found, skip to the final step and output \"null\".\\n2. Think of insightful perspectives and generate a devil's advocate.\"\"\",\n",
    "        \"validation_criteria\": \"\"\"gives an interesting perspective but not too controversial\"\"\",\n",
    "        \"proactive_tool_description\": \"\"\"When it would be useful for the user to see a devil's advocate opinion (a steel-man argument supporting a viewpoint different from their own).\"\"\",\n",
    "        \"proactive_tool_example\": \"\"\"Conversation: Transcript mentions \"Climate change is a hoax.\"\n",
    "Insight: Most scientists confirm climate change's reality; evidence is in global trends\"\"\",\n",
    "        \"examples\": \"\"\"\n",
    "1. Conversation: Transcript mentions \"Climate change is a hoax.\"\n",
    "Insight: Most scientists confirm climate change's reality; evidence is in global trends\n",
    "\n",
    "2. Conversation: Transcript mentions \"Vaccines cause autism\".\n",
    "Insight: Numerous studies show no vaccine-autism link; vaccines prevent disease outbreaks\n",
    "\n",
    "3. Conversation: Transcript mentions \"Artificial intelligence will replace all human jobs.\"\n",
    "Insight: AI will create new jobs and industries, not just replace old ones\n",
    "\"\"\",\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field, validator\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "\n",
    "class AgentInsight(BaseModel):\n",
    "        \"\"\"\n",
    "        Query for an insight generation process\n",
    "        \"\"\"\n",
    "        agent_insight: str = Field(\n",
    "             description=\"the short insight generated by the agent\")\n",
    "        reference_source: str = Field(\n",
    "             description=\"the most useful source used to generate this insight\", default=\"\")\n",
    "\n",
    "agent_insight_parser = PydanticOutputParser(pydantic_object=AgentInsight)\n",
    "\n",
    "def format_list_data(list_data: list):\n",
    "    return \"\\n\".join([f\"{i+1}. {example}\" for i, example in enumerate(list_data)])\n",
    "\n",
    "def expert_agent_prompt_maker(expert_agent_config, conversation_transcript, insights_history: list = [], final_command=\"\"):\n",
    "    # Populating the blueprint string with values from the agent_config dictionary\n",
    "    if final_command != \"\":\n",
    "        final_command = \"\\n\\n\" + final_command\n",
    "    expert_agent_prompt = expert_agent_prompt_blueprint.format(**expert_agent_config, final_command=final_command, conversation_transcript=conversation_transcript, insights_history=format_list_data(insights_history), format_instructions=agent_insight_parser.get_format_instructions())\n",
    "    return expert_agent_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.agents.tools import Tool\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents import AgentType\n",
    "\n",
    "open_ai_api_key = os.environ.get(\"OPEN_AI_API_KEY\")\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, openai_api_key=open_ai_api_key, model=\"gpt-4-1106-preview\")\n",
    "\n",
    "class SearchInput(BaseModel):\n",
    "    query: str = Field(description=\"a search query\")\n",
    "\n",
    "agent = initialize_agent([\n",
    "        Tool(\n",
    "            name=\"Search_Engine\",\n",
    "            func=custom_search,\n",
    "            coroutine=arun_search_tool_for_agents,\n",
    "            description=\"Pass this specific targeted queries and/or keywords to quickly search the WWW to retrieve vast amounts of information on virtually any topic, spanning from academic research and navigation to history, entertainment, and current events. It's a tool for understanding, navigating, and engaging with the digital world's vast knowledge.\",\n",
    "            args_schema=SearchInput\n",
    "        ),\n",
    "    ], llm, agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION, max_iterations=2, early_stopping_method=\"generate\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " And if you look at the progress of things, it's getting better and better and better. I mean, if you, you know. Yeah. We're a little bit of a stalemate here. Democracy's really blossomed between World War II and the year 2000, especially in the eighties and nineties, you had an incredible wave of fall, you know, where many, many authoritarian, regimes fell and were replaced by democracies. I think around 2015, the acceleration kind of came to a standstill a little bit. There's some good news in some countries and there's bad news in others. Like in the last 10 years, you've had, for example, the Philippines has gone backwards., Thailand has gone backwards. Bangladesh has gone backwards. Turkey has gone backwards. That's like a half billion people right there. So you've had some positives, like, you know, there was positive movement forward in Armenia, Malaysia, some other countries, but we're kind of at a stalemate right now. And what most people fear about where we are right now, who I respect, is what is the digital, transformation of the world due to this like progress of democracy or of open societies. And that's what concerns me the most. Oh, interesting. So I've, and we'll talk about one of the most fascinating technologies, which is Bitcoin, how it can help. But I have a sense that technology, like most technological innovations will give power, to the individuals, will fight authoritarian governments as opposed to give more power to authoritarian governments. But your sense is there's ways to give for technology to be utilized as a tool for the abuse of the citizenry. I've seen both. In my work at Ahrefs, I started by helping to put together backpacks with foreign information\n",
      " that we sent to the Cuban underground library movement. So in Cuba, you know, to own a book at the time, you had to have the government's permission. There's very little internet penetration. Okay. So we would send in movies, you know, V for Vendetta, dubbed into Spanish, and people would sit inside their homes and they'd watch it and they would answer questions with each other. It was awful.\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m### Plan to Generate the \"Insight\"\n",
      "1. Identify suspected falsy claims from the conversation:\n",
      "   - The claim about the progress of democracy coming to a standstill around 2015.\n",
      "   - The claim about the Philippines, Thailand, Bangladesh, and Turkey going backwards in terms of democracy.\n",
      "   - The claim about positive movements in democracy in Armenia and Malaysia.\n",
      "   - The claim about the digital transformation's impact on the progress of democracy or open societies.\n",
      "   - The claim about technology giving power to individuals to fight authoritarian governments.\n",
      "\n",
      "2. Select the claim to fact-check:\n",
      "   - The claim about the progress of democracy coming to a standstill around 2015 seems to be the most impactful and verifiable claim.\n",
      "\n",
      "3. Search for the truth to the claim:\n",
      "   - Use the Search_Engine tool to verify the claim about the progress of democracy since 2015.\n",
      "\n",
      "4. Generate the \"Insight\":\n",
      "   - The \"Insight\" should be short and concise (<10 words), replace words with symbols to shorten the overall length where possible except for names. Make sure the \"Insight\" is insightful, up to par with the examples, specialized to your role (debunks the falsy claim, and provides brief elaboration), otherwise skip it and return \"null\".\n",
      "\n",
      "the \"Insight\" should be short and concise (<10 words), replace words with symbols to shorten the overall length where possible except for names. Make sure the \"Insight\" is insightful, up to par with the examples, specialized to your role (debunks the falsy claim, and provides brief elaboration), otherwise skip it and return \"null\".\n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Search_Engine\",\n",
      "  \"action_input\": {\n",
      "    \"query\": \"progress of democracy since 2015\"\n",
      "  }\n",
      "}\n",
      "```\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mRes 1:\n",
      "Title: Democracy - Our World in Data\n",
      "Source:https://ourworldindata.org/democracy\n",
      "Snippet: Many more countries have become democracies over the last two hundred years. The chart shows — based on data from Regimes of the World (RoW) — that a much ...\n",
      "\n",
      "\n",
      "Res 2:\n",
      "Title: Global State of Democracy Report 2021 - International IDEA\n",
      "Source:https://www.idea.int/gsod-2021/global-report\n",
      "Snippet: Fewer countries than ever are moving towards democracy; since 2015, the absolute number of democracies has been declining (Figure 3). As of August 2021, the ...\n",
      "\n",
      "\n",
      "Res 3:\n",
      "Title: Democracy in Crisis | Freedom House\n",
      "Source:https://freedomhouse.org/report/freedom-world/2018/democracy-crisis\n",
      "Snippet: Democracy faced its most serious crisis in decades in 2017 as its basic tenets—including guarantees of free and fair elections, the rights of minorities, ...\n",
      "\n",
      "\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe search results provide information that can be used to fact-check the claim about the progress of democracy since 2015. The second result from International IDEA seems particularly relevant as it mentions that since 2015, the number of democracies has been declining. This supports the claim made in the conversation that the progress of democracy came to a standstill around 2015. Therefore, the claim does not appear to be falsy and does not need to be debunked.\n",
      "\n",
      "Given this information, the \"Insight\" should reflect the confirmation of the claim rather than debunking it. However, the guidelines specify that the \"Insight\" should debunk a falsy claim, and since the claim is supported by the source, there is no falsy claim to debunk. Therefore, the appropriate response is \"null\".\n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": {\n",
      "    \"agent_insight\": \"null\",\n",
      "    \"reference_source\": \"https://www.idea.int/gsod-2021/global-report\"\n",
      "  }\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'agent_insight': 'null',\n",
       " 'reference_source': 'https://www.idea.int/gsod-2021/global-report'}"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_transcript = generate_test_input()\n",
    "print(test_transcript)\n",
    "agent_key = expert_agent_config_list[\"FactChecker\"]\n",
    "agent_prompt = expert_agent_prompt_maker(agent_key, test_transcript, [])\n",
    "# print(agent_prompt)\n",
    "await agent.arun(agent_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent2 = initialize_agent([\n",
    "        Tool(\n",
    "            name=\"Search_Engine\",\n",
    "            func=custom_search,\n",
    "            description=\"Pass this specific targeted queries and/or keywords to quickly search the WWW to retrieve vast amounts of information on virtually any topic, spanning from academic research and navigation to history, entertainment, and current events. It's a tool for understanding, navigating, and engaging with the digital world's vast knowledge.\",\n",
    "            args_schema=SearchInput\n",
    "        ),\n",
    "    ], llm, agent=AgentType.OPENAI_FUNCTIONS, max_iterations=2, early_stopping_method=\"generate\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " And if you look at the progress of things, it's getting better and better and better. I mean, if you, you know. Yeah. We're a little bit of a stalemate here. Democracy's really blossomed between World War II and the year 2000, especially in the eighties and nineties, you had an incredible wave of fall, you know, where many, many authoritarian, regimes fell and were replaced by democracies. I think around 2015, the acceleration kind of came to a standstill a little bit. There's some good news in some countries and there's bad news in others. Like in the last 10 years, you've had, for example, the Philippines has gone backwards., Thailand has gone backwards. Bangladesh has gone backwards. Turkey has gone backwards. That's like a half billion people right there. So you've had some positives, like, you know, there was positive movement forward in Armenia, Malaysia, some other countries, but we're kind of at a stalemate right now. And what most people fear about where we are right now, who I respect, is what is the digital, transformation of the world due to this like progress of democracy or of open societies. And that's what concerns me the most. Oh, interesting. So I've, and we'll talk about one of the most fascinating technologies, which is Bitcoin, how it can help. But I have a sense that technology, like most technological innovations will give power, to the individuals, will fight authoritarian governments as opposed to give more power to authoritarian governments. But your sense is there's ways to give for technology to be utilized as a tool for the abuse of the citizenry. I've seen both. In my work at Ahrefs, I started by helping to put together backpacks with foreign information\n",
      " that we sent to the Cuban underground library movement. So in Cuba, you know, to own a book at the time, you had to have the government's permission. There's very little internet penetration. Okay. So we would send in movies, you know, V for Vendetta, dubbed into Spanish, and people would sit inside their homes and they'd watch it and they would answer questions with each other. It was awful.\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m### Plan for Generating an \"Insight\"\n",
      "1. The conversation discusses the state of democracy and the impact of digital transformation on it, with a focus on recent changes in specific countries. The \"Insight\" should provide a quantitative perspective on the current state of democracy or digital transformation's effect on it.\n",
      "2. The most important quantitative data needed to generate the \"Insight\" could be recent statistics on the state of democracy worldwide or the rate of internet penetration in countries that have experienced democratic backsliding. This data should come from reputable sources like Freedom House or the International Telecommunication Union.\n",
      "3. the \"Insight\" should be short and concise (<10 words), replace words with symbols to shorten the overall length where possible except for names. Make sure the \"Insight\" is insightful, up to par with the examples, specialized to your role (contains quantitative data), otherwise skip it and return \"null\".\n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Search_Engine\",\n",
      "  \"action_input\": {\n",
      "    \"query\": \"current state of democracy statistics 2023\"\n",
      "  }\n",
      "}\n",
      "```\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kenji/mambaforge/envs/tosg/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/home/kenji/mambaforge/envs/tosg/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/home/kenji/mambaforge/envs/tosg/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Observation: \u001b[36;1m\u001b[1;3m<result0>\n",
      "Title: The Global State of Democracy 2023: The New Checks and Balances | International IDEA\n",
      "Link: https://www.idea.int/publications/catalogue/global-state-democracy-2023-new-checks-and-balances\n",
      "Snippet: The global state of democracy in 2023 is complex, fluid and unequal. Across every region of the world, democracy has continued to contract, ...\n",
      "Summarized Page: <p>Main navigation Main navigation Explore menu Breadcrumb The Global State of Democracy 2023 The global state of democracy in 2023 is complex, fluid and unequal. Indeed, while The Global State of Democracy 2023 shows some declines in countries that had been thought to be healthy democracies, at the same time there were encouraging improvements in countries where the level of oppression has been constant for years. Countervailing institutions include relatively new entities, such as human rights organizations and electoral management bodies, as well as civil society networks, popular movements and investigative journalists, which all play an irreplaceable role in ensuring democracy continues to be of and by the people. Details Contents ForewordPrefaceExecutive summary Introduction 1. Leave us your feedback, and we’ll get back to you The Global State of Democracy 2023 Give us feedback Do you have a question or feedback about this publication? Sweden’s Democracy in a Global Perspective Perspectives 'The most bitter cigarette': How Europe’s gas dependence is a hazard for democracy Follow us Get the best of International IDEA Need Help? Postal Address:Strömsborgsbron 1  SE-103 34 StockholmSweden Footer menu Cookie Notice \n",
      "              Our Cookies Policy and\n",
      "              Privacy Policy have changed.</p>\n",
      "</result0>\n",
      "\n",
      "<result1>\n",
      "Title: The Global State of Democracy in 2023: A new set of checks and balances paves the way ahead | International IDEA\n",
      "Link: https://www.idea.int/blog/global-state-democracy-2023-new-set-checks-and-balances-paves-way-ahead\n",
      "Snippet: The fifth edition of International IDEA's Global State of Democracy report closes out an eventful year.\n",
      "Summarized Page: <p>Main navigation Main navigation Explore menu Breadcrumb The Global State of Democracy in 2023: A new set of checks and balances paves the way ahead The fifth edition of International IDEA’s Global State of Democracy report closes out an eventful year. Multiple crises have battered the world, but inspirational wins in gender equality, indigenous communities’ rights, the fight against corruption, and enforcement of the rule of law are important flags marking the path forward. Our latest data show that virtually half the countries in our dataset have suffered a notable decline in at least one factor of democratic performance over the last five years. Countervailing institutions  Countervailing institutions are the set of governmental and non-governmental institutions that balance the distribution of power between the branches of government and ensure that popular priorities regularly and consistently feature in decision making. They also include myriad organizations, institutions and popular movements that act to protect equal access to and public control of decision making, such as civil society and other political institutions (e.g., ombuds offices, anti-corruption commissions, electoral management bodies or EMBs, ethics bodies, etc). Successes to celebrate  Cross-institutional collaboration has resulted in several wins in recent years. Postal Address:Strömsborgsbron 1  SE-103 34 StockholmSweden Footer menu Cookie Notice \n",
      "              Our Cookies Policy and\n",
      "              Privacy Policy have changed.</p>\n",
      "</result1>\n",
      "\n",
      "<result2>\n",
      "Title: Explore the Data | Freedom House\n",
      "Link: https://freedomhouse.org/report/nations-transit/2023/war-deepens-regional-divide/explore-data\n",
      "Snippet: In 2023, Democracy Scores declined in 11 out of the 29 countries in the report, and 7 countries earned improvements. Yet civic activists and democratic ...\n",
      "Summarized Page: <p>Primary Navigation Quicklinks Mega Menu Explore the Data Explore the Report Read the Full Report Read the essays and review the data from our Nations in Transit 2023. Explore the Map In 2023, Democracy Scores declined in 11 out of the 29 countries in the report, and 7 countries earned improvements. Yet civic activists and democratic leaders continued to strive for better governance across the diverse region. Policy Recommendations To counter the spread of antidemocratic practices in Europe and Eurasia, democratic countries—especially the United States and European Union (EU) member states—should consider pursuing the following policy priorities. Join the Freedom House weekly newsletter Footer Main Menu Address 1850 M St. NW Floor 11\n",
      "      Washington, DC 20036 General Inquiries Press & Media Footer Social Menu Follow Footer</p>\n",
      "</result2>\n",
      "\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe search results provided information on the current state of democracy, with the first result indicating that democracy has continued to contract globally. The second result highlights that half of the countries in the dataset have suffered a decline in democratic performance over the last five years. The third result from Freedom House states that in 2023, Democracy Scores declined in 11 out of the 29 countries in the report. This data from Freedom House seems to be the most relevant and recent, providing a clear statistic that can be used to generate an \"Insight\".\n",
      "\n",
      "Given the guidelines and the information obtained, the \"Insight\" should focus on the recent decline in democracy scores as reported by Freedom House, which is a reputable source for such data. The \"Insight\" should be short, concise, and contain quantitative data.\n",
      "\n",
      "The \"Insight\" could be: \"2023: Democracy scores ↓ in 11/29 countries\".\n",
      "\n",
      "The reference source for this \"Insight\" would be the Freedom House link provided in the search results.\n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": {\n",
      "    \"agent_insight\": \"2023: Democracy scores ↓ in 11/29 countries\",\n",
      "    \"reference_source\": \"https://freedomhouse.org/report/nations-transit/2023/war-deepens-regional-divide/explore-data\"\n",
      "  }\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'agent_insight': '2023: Democracy scores ↓ in 11/29 countries',\n",
       " 'reference_source': 'https://freedomhouse.org/report/nations-transit/2023/war-deepens-regional-divide/explore-data'}"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_transcript = generate_test_input()\n",
    "print(test_transcript)\n",
    "agent_key = expert_agent_config_list[\"Statistician\"]\n",
    "agent_prompt = expert_agent_prompt_maker(agent_key, test_transcript, [])\n",
    "# print(agent_prompt)\n",
    "agent.run(agent_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tosg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
