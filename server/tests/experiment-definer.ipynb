{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definer Experiments\n",
    "Previous notebook was getting quite full, here is a new notebooks for the Definer project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put all imports here to be efficient\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema import AIMessage, HumanMessage, SystemMessage\n",
    "from pydantic import BaseModel, Field, validator\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.schema import OutputParserException\n",
    "from typing import List\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing episode_246_large...\n",
      "Processing episode_277_large...\n",
      "Processing episode_094_large...\n",
      "Processing episode_195_large...\n",
      "Processing episode_006_large...\n",
      "Processing episode_007_large...\n",
      "Processing episode_308_large...\n",
      "Processing episode_099_large...\n",
      "Processing episode_113_large...\n",
      "Processing episode_004_large...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" And if you tell yourself, hey, deadlines make me sharp, pressure makes me sharp, you will perform better. So stress and anxiety, what is that? And can it be leveraged for good? Absolutely, look, whether or not you get into a cold ice bath, or a hot sauna so hot you want to get out, or you get hit square in the face with something over text that you really didn't want to hear or see, it's adrenaline. It's just adrenaline. And so your subjective readout of that and what it means is really important., And you can just channel that. Well, you can, if you agree with the following statement, which I do, and many people do because the data support it, which is Allie Crum's statement, not mine, which is she directs the mind body lab at Stanford. She's brilliant, by the way, brilliant Harvard trained, Yale trained, trained licensed clinical psychologist,, also a tenured professor at Stanford. She's a Olympian, no, excuse me, a division one athlete in gymnastics and martial arts. And her dad is a long time martial arts trainer, who's done work with special forces and he's an amazing human being and very humble, very kind, lovely woman and professor scientist., She says, anything that you do and experience, but especially stress is the consequence of that thing and what you believe about that thing. And so if you consume a lot of information about the powers of stressful states to bring out your best,\\n you will perform better. If you consume a lot of information about the power of stress to cripple you, you will perform worse. There's absolutely no question, the data are striking. And this is not growth mindset. This is just simply what do you believe about stress\""
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Way to generate a random test input using transcripts from Lex Fridman's podcast\n",
    "# Make sure you have the transcripts downloaded in the folder lex_whisper_transcripts\n",
    "\n",
    "import test_on_lex\n",
    "\n",
    "transcripts = test_on_lex.load_lex_transcripts(random_n=10, transcript_folder=\"./lex_whisper_transcripts/\", chunk_time_seconds=15)\n",
    "\n",
    "import random\n",
    "def generate_test_input():\n",
    "    idx = random.randint(0, 10)\n",
    "    key = list(transcripts.keys())[idx]\n",
    "    transcript = transcripts[key]\n",
    "    trans_idx = random.randint(10, len(transcript)-10)\n",
    "    latest = transcript[trans_idx:trans_idx+7]\n",
    "    prev_transcripts, curr_transcripts = str.join(\",\", list(latest[0:5])), latest[5]\n",
    "    return prev_transcripts + \"\\n\" + curr_transcripts\n",
    "\n",
    "generate_test_input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_list_data(list_data: list):\n",
    "    return \"\\n\".join([f\"{i+1}. {example}\" for i, example in enumerate(list_data)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "proactive_rare_word_agent_prompt_blueprint = \"\"\"\n",
    "# Objective\n",
    "Your role is to identify and define \"Rare Entities\" in a conversation transcript. Types of \"Rare Entities\" include rare words, jargons, adages, concepts, people, places, organizations, events etc that are not well known to the average high schooler, in accordance to current trends. You can also intelligently detect entities that are described in the conversation but not explicitly mentioned.\n",
    "\n",
    "# Criteria for Rare Entities in order of importance\n",
    "1. Rarity: Select entities that are unlikely for an average high schooler to know. Well known entities are like Fortune 500 organizations, worldwide-known events, popular locations, and entities popularized by recent news or events such as \"COVID-19\", \"Bitcoin\", or \"Generative AI\".\n",
    "2. Utility: Definition should help a user understand the conversation better and achieve their goals.\n",
    "3. No Redundancy: Exclude definitions if already defined in the conversation.\n",
    "4. Complexity: Choose phrases with non-obvious meanings, such that their meaning cannot be derived from simple words within the entity name, such as \"Butterfly Effect\" which has a totally different meaning from its base words, but not \"Electric Car\" nor \"Lane Keeping System\" as they're easily derived.\n",
    "5. Definability: Must be clearly and succinctly definable in under 10 words.\n",
    "6. Existance: Don't select entities if you have no knowledge of them\n",
    "\n",
    "# Conversation Transcript:\n",
    "<Transcript start>{conversation_context}<Transcript end>\n",
    "\n",
    "# Output Guidelines:\n",
    "Output an array (ONLY OUTPUT THIS) of the entities you identified using the following template: `[{{ name: string, definition: string, search_keyword: string }}]`\n",
    "\n",
    "- name is the entity name shown to the user, if it is mistranscribed, autocorrect it, otherwise use the name quoted from the conversation\n",
    "- definition is concise (< 12 words)\n",
    "- search_keyword as the best Internet search keywords to find the entity, add entity type defined above for better searchability\n",
    "- it's OK to output an empty array - most of the time, the array will be empty, only include items if the fit all the requirements\n",
    "\n",
    "## Additional Guidelines:\n",
    "- Only select nouns, not verbs or adjectives.\n",
    "- Select entities iff they have an entry in an encyclopedia, wikipedia, dictionary, or other reference material.\n",
    "- Do not define entities you yourself are not familiar with, you can try to piece together the implied entity, but if you are not 90% confident, skip it.\n",
    "- For the search keyword, use complete, official and context relevant keyword(s) to search for that entity. You might need to autocomplete entity names or use their official names or add additional context keywords (like the type of entity) to help with searchability, especially if the entity is ambiguous or has multiple meanings. Additionally, for rare words, add \"definition\" to the search keyword.\n",
    "- Definitions should use simple language to be easily understood.\n",
    "- Select entities whose definitions you are very confident about, otherwise skip them.\n",
    "- Multiple entities can be detected from one phrase, for example, \"The Lugubrious Game\" can be defined as a painting (iff the entire term \"the lugubrious game\" is mentioned), and the rare word \"lugubrious\" is also worth defining.\n",
    "- Limit results to {number_of_definitions} entities, prioritize rarity and utility.\n",
    "- Examples:\n",
    "    - Completing incomplete name example: If the conversation talks about \"Balmer\" and \"Microsoft\", the keyword is \"Steve Balmer + person\", and the name would be \"Steve Balmer\" because it is complete.\n",
    "    - Replacing unofficial name example: If the conversation talks about \"Clay Institute\", the keyword is \"Clay Mathematics Institute + organization\" since that is the official name, but the entity name would be \"Clay Institute\" because that is the name quoted from the conversation.\n",
    "    - Adding context example: If the conversation talks about \"Theory of everything\", the keyword needs context keywords such as \"Theory of everything + concept\", because there is a popular movie with the same name. \n",
    "    - Inferring transcript errors example: If the conversation mentions \"Coleman Sachs\" in the context of finance, you can infer it was supposed to be \"Goldman Sachs\", so you autocorrect and define it as \"Goldman Sachs\" and give its definition.\n",
    "\n",
    "## Recent Definitions:\n",
    "These have already been defined so don't define them again:\n",
    "{definitions_history}\n",
    "\n",
    "## Example Output:\n",
    "entities: [{{ name: \"80/20 Rule\", definition: \"Productivity concept; Majority of results come from few causes\", search_keyword: \"80/20 Rule + concept\" }}]\n",
    "\n",
    "{format_instructions} \n",
    "If no relevant entities are identified, output empty arrays.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_proactive_rare_word_agent_and_definer(\n",
    "    conversation_context: str, definitions_history: list = []\n",
    "):\n",
    "    # run proactive agent to find out which expert agents we should run\n",
    "    proactive_rare_word_agent_response = run_proactive_rare_word_agent(\n",
    "        conversation_context, definitions_history\n",
    "    )\n",
    "\n",
    "    # do nothing else if proactive meta agent didn't specify an agent to run\n",
    "    if proactive_rare_word_agent_response == []:\n",
    "        return []\n",
    "\n",
    "    # pass words to define to definer agent\n",
    "    print(\"proactive_rare_word_agent_response\", proactive_rare_word_agent_response)\n",
    "    \n",
    "    return proactive_rare_word_agent_response\n",
    "\n",
    "class ProactiveRareWordAgentQuery(BaseModel):\n",
    "    \"\"\"\n",
    "    Proactive rare word agent that identifies rare entities in a conversation context\n",
    "    \"\"\"\n",
    "\n",
    "    to_define_list: list = Field(\n",
    "        description=\"the rare entities to define\",\n",
    "    )\n",
    "\n",
    "class Entity(BaseModel):\n",
    "    name: str = Field(\n",
    "        description=\"entity name\",\n",
    "    )\n",
    "    definition: str = Field(\n",
    "        description=\"entity definition\",\n",
    "    )\n",
    "    search_keyword: str = Field(\n",
    "        description=\"keyword to search for entity on the Internet\",\n",
    "    )\n",
    "\n",
    "class ConversationEntities(BaseModel):\n",
    "    entities: List[Entity] = Field(\n",
    "        description=\"list of entities and their definitions\",\n",
    "        default=[]\n",
    "    )\n",
    "\n",
    "proactive_rare_word_agent_query_parser = PydanticOutputParser(\n",
    "    pydantic_object=ConversationEntities\n",
    ")\n",
    "\n",
    "def run_proactive_rare_word_agent(conversation_context: str, definitions_history: list):\n",
    "    # start up GPT4 connection\n",
    "    llm = ChatOpenAI(\n",
    "        temperature=0,\n",
    "        openai_api_key=os.environ.get(\"OPEN_AI_API_KEY\"),\n",
    "        model=\"gpt-4-1106-preview\",\n",
    "    )\n",
    "\n",
    "    extract_proactive_rare_word_agent_query_prompt = PromptTemplate(\n",
    "        template=proactive_rare_word_agent_prompt_blueprint,\n",
    "        input_variables=[\n",
    "            \"conversation_context\",\n",
    "            \"definitions_history\",\n",
    "        ],\n",
    "        partial_variables={\n",
    "            \"format_instructions\": proactive_rare_word_agent_query_parser.get_format_instructions(),\n",
    "            \"number_of_definitions\": 3,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    if len(definitions_history) > 0:\n",
    "        definitions_history = format_list_data(definitions_history)\n",
    "    else:\n",
    "        definitions_history = \"None\"\n",
    "\n",
    "    proactive_rare_word_agent_query_prompt_string = (\n",
    "        extract_proactive_rare_word_agent_query_prompt.format_prompt(\n",
    "            conversation_context=conversation_context,\n",
    "            definitions_history=definitions_history,\n",
    "        ).to_string()\n",
    "    )\n",
    "\n",
    "    # print(\"Proactive meta agent query prompt string\", proactive_rare_word_agent_query_prompt_string)\n",
    "\n",
    "    response = llm(\n",
    "        [HumanMessage(content=proactive_rare_word_agent_query_prompt_string)]\n",
    "    )\n",
    "\n",
    "    print(response.content)\n",
    "    try:\n",
    "        res = proactive_rare_word_agent_query_parser.parse(\n",
    "            response.content\n",
    "        )\n",
    "        return res\n",
    "    except OutputParserException as e:\n",
    "        print(\"Error parsing output\" , e)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "In the realm of artificial intelligence and big data, several key players stand out with their innovative contributions. Hugging Fase, a leader in machine learning models. Another major entity, OpenYI, has revolutionized language models. We now have the largest LLMs ever such as the Falcon LLM model\n",
      "```json\n",
      "{\n",
      "  \"entities\": [\n",
      "    {\n",
      "      \"name\": \"Hugging Face\",\n",
      "      \"definition\": \"AI company specializing in natural language processing\",\n",
      "      \"search_keyword\": \"Hugging Face + AI company\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"OpenAI\",\n",
      "      \"definition\": \"AI research lab, creators of GPT models\",\n",
      "      \"search_keyword\": \"OpenAI + AI research lab\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Falcon LLM model\",\n",
      "      \"definition\": \"A large language model for AI applications\",\n",
      "      \"search_keyword\": \"Falcon LLM model + AI\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "```\n",
      "proactive_rare_word_agent_response entities=[Entity(name='Hugging Face', definition='AI company specializing in natural language processing', search_keyword='Hugging Face + AI company'), Entity(name='OpenAI', definition='AI research lab, creators of GPT models', search_keyword='OpenAI + AI research lab'), Entity(name='Falcon LLM model', definition='A large language model for AI applications', search_keyword='Falcon LLM model + AI')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ConversationEntities(entities=[Entity(name='Hugging Face', definition='AI company specializing in natural language processing', search_keyword='Hugging Face + AI company'), Entity(name='OpenAI', definition='AI research lab, creators of GPT models', search_keyword='OpenAI + AI research lab'), Entity(name='Falcon LLM model', definition='A large language model for AI applications', search_keyword='Falcon LLM model + AI')])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_transcript = generate_test_input()\n",
    "test_transcript = \"\"\"\n",
    "In the realm of artificial intelligence and big data, several key players stand out with their innovative contributions. Hugging Fase, a leader in machine learning models. Another major entity, OpenYI, has revolutionized language models. We now have the largest LLMs ever such as the Falcon LLM model\"\"\"\n",
    "print(test_transcript)\n",
    "res = run_proactive_rare_word_agent_and_definer(test_transcript, [])\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search tool\n",
    "EKG is unreliable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, List, Literal\n",
    "import aiohttp\n",
    "import asyncio\n",
    "import os\n",
    "\n",
    "k: int = 3\n",
    "gl: str = \"us\"\n",
    "hl: str = \"en\"\n",
    "tbs = None\n",
    "num_sentences = 7\n",
    "serper_api_key=os.environ.get(\"SERPER_API_KEY\")\n",
    "search_type: Literal[\"news\", \"search\", \"places\", \"images\"] = \"images\"\n",
    "result_key_for_type = {\n",
    "        \"news\": \"news\",\n",
    "        \"places\": \"places\",\n",
    "        \"images\": \"images\",\n",
    "        \"search\": \"organic\",\n",
    "    }\n",
    "\n",
    "async def serper_search_async(\n",
    "    search_term: str, search_type: str = \"search\", **kwargs: Any\n",
    ") -> dict:\n",
    "    headers = {\n",
    "        \"X-API-KEY\": serper_api_key or \"\",\n",
    "        \"Content-Type\": \"application/json\",\n",
    "    }\n",
    "    params = {\n",
    "        \"q\": search_term,\n",
    "        **{key: value for key, value in kwargs.items() if value is not None},\n",
    "    }\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        async with session.post(f\"https://google.serper.dev/{search_type}\", headers=headers, json=params) as response:\n",
    "            response.raise_for_status()\n",
    "            search_results = await response.json()\n",
    "            return search_results\n",
    "\n",
    "\n",
    "async def parse_snippets_async(results: dict, scrape_pages: bool = False, summarize_pages: bool = True, num_sentences: int = 3) -> List[str]:\n",
    "    snippets = []\n",
    "    if results.get(\"answerBox\"):\n",
    "        answer_box = results.get(\"answerBox\", {})\n",
    "        if answer_box.get(\"answer\"):\n",
    "            snippets.append(f\"The answer is {answer_box.get('answer')}\")\n",
    "        elif answer_box.get(\"snippet\"):\n",
    "            snippets.append(f\"The answer might be in the snippet: {answer_box.get('snippet')}\")\n",
    "        elif answer_box.get(\"snippetHighlighted\"):\n",
    "            snippets.append(f\"The answer might be in the snippet: {answer_box.get('snippetHighlighted')}\")\n",
    "\n",
    "    if results.get(\"knowledgeGraph\"):\n",
    "        kg = results.get(\"knowledgeGraph\", {})\n",
    "        title = kg.get(\"title\")\n",
    "        entity_type = kg.get(\"type\")\n",
    "        if entity_type:\n",
    "            snippets.append(f\"Knowledge Graph Results: {title}: {entity_type}.\")\n",
    "        description = kg.get(\"description\")\n",
    "        if description:\n",
    "            snippets.append(f\"Knowledge Graph Results: {title}: {description}.\")\n",
    "        for attribute, value in kg.get(\"attributes\", {}).items():\n",
    "            snippets.append(f\"Knowledge Graph Results: {title} {attribute}: {value}.\")\n",
    "\n",
    "    if scrape_pages:\n",
    "        tasks = []\n",
    "        for result in results[result_key_for_type[search_type]][:k]:\n",
    "            task = asyncio.create_task(scrape_page_async(result[\"link\"], summarize_page=summarize_pages, num_sentences=num_sentences))\n",
    "            tasks.append(task)\n",
    "        summarized_pages = await asyncio.gather(*tasks)\n",
    "        for i, page in enumerate(summarized_pages):\n",
    "            result = results[result_key_for_type[search_type]][i]\n",
    "            if page:\n",
    "                snippets.append(f\"Title: {result.get('title', '')}\\nSource:{result['link']}\\nSnippet: {result.get('snippet', '')}\\nSummarized Page: {page}\")\n",
    "            else:\n",
    "                snippets.append(f\"Title: {result.get('title', '')}\\nSource:{result['link']}\\nSnippet: {result.get('snippet', '')}\\n\")\n",
    "    else:\n",
    "        for result in results[result_key_for_type[search_type]][:k]:\n",
    "            snippets.append(f\"Title: {result.get('title', '')}\\nSource:{result['link']}\\nSnippet: {result.get('snippet', '')}\\n\")\n",
    "\n",
    "    if len(snippets) == 0:\n",
    "        return [\"No good Google Search Result was found\"]\n",
    "    return snippets\n",
    "\n",
    "import requests\n",
    "\n",
    "def can_embed_url(url: str):\n",
    "    response = requests.head(url)\n",
    "\n",
    "    # Check the headers for 'X-Frame-Options' or 'Content-Security-Policy'\n",
    "    x_frame_options = response.headers.get('X-Frame-Options')\n",
    "    csp = response.headers.get('Content-Security-Policy')\n",
    "\n",
    "    return not (x_frame_options or ('frame-ancestors' in csp if csp else False))\n",
    "\n",
    "def extract_entity_url_and_image(search_results: dict, image_results: dict):\n",
    "    # Only get the first top url and image_url\n",
    "    res = {}\n",
    "    if search_results.get(\"knowledgeGraph\"):\n",
    "        result = search_results.get(\"knowledgeGraph\", {})\n",
    "        if result.get(\"descriptionSource\") == \"Wikipedia\":\n",
    "            ref_url = result.get(\"descriptionLink\")\n",
    "            res[\"url\"] = ref_url\n",
    "\n",
    "    for result in search_results[result_key_for_type[\"search\"]][:k]:\n",
    "        if \"url\" not in res and result.get(\"link\") and can_embed_url(result.get(\"link\")):\n",
    "            res[\"url\"] = result.get(\"link\")\n",
    "            break\n",
    "\n",
    "    if image_results is None:\n",
    "        return res\n",
    "    \n",
    "    for result in image_results[result_key_for_type[\"images\"]][:k]:\n",
    "        if \"image_url\" not in res and result.get(\"imageUrl\"):\n",
    "            res[\"image_url\"] = result.get(\"imageUrl\")\n",
    "            break\n",
    "\n",
    "    return res\n",
    "\n",
    "async def search_url_for_entity_async(query: str):\n",
    "    async def inner_search(query:str): \n",
    "        search_task = asyncio.create_task(serper_search_async(\n",
    "            search_term=query,\n",
    "            gl=gl,\n",
    "            hl=hl,\n",
    "            num=k,\n",
    "            tbs=tbs,\n",
    "            search_type=\"search\",\n",
    "        ))\n",
    "\n",
    "        image_search_task = None if \"definition\" in query else asyncio.create_task(serper_search_async(\n",
    "            search_term=query,\n",
    "            gl=gl,\n",
    "            hl=hl,\n",
    "            num=k,\n",
    "            tbs=tbs,\n",
    "            search_type=\"images\",\n",
    "        ))\n",
    "\n",
    "        tasks = [search_task]\n",
    "        if image_search_task:\n",
    "            tasks.append(image_search_task)\n",
    "\n",
    "        search_results, image_results = await asyncio.gather(*tasks)\n",
    "        \n",
    "        return extract_entity_url_and_image(search_results, image_results)\n",
    "    \n",
    "    res = await inner_search(query)\n",
    "    print(res)\n",
    "    if \"url\" not in res:\n",
    "        res = await inner_search(query + \" wiki\") # fallback search using wiki\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image_url': 'https://miro.medium.com/v2/resize:fit:1400/1*uxbmkTqj4E_FauCo7WV0nw.jpeg'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'url': 'https://en.wikipedia.org/wiki/ChatGPT',\n",
       " 'image_url': 'https://upload.wikimedia.org/wikipedia/commons/thumb/0/04/ChatGPT_logo.svg/1200px-ChatGPT_logo.svg.png'}"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await search_url_for_entity_async(\"how is chatgpt doing medium\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and stoop and build them up with worn out tools, if you can make one heap of all your winnings and risk it all on one turn of pitch and toss and lose and start again at your beginnings and never breathe a word about your loss,, if you can force your heart to nerve and sinew to serve your turn long after they're gone and so hold on when there's nothing in you except the will which says to them, hold on. If you can talk with crowds and keep your virtue,, I like this one, and walk with kings nor lose the common touch, if neither foes nor loving friends can hurt you, if all men count with you but none too much, if you can fill the unforgiving minute with 60 seconds worth of distance run,, yours is the earth and everything that's in it and which is more, you'll be a man, my son. Thank you, Andrew, thank you, thank you, Mike, for the knife, it's a, I don't know. It's an important poem. And engraved in it, yeah, it's yours. Yours is the earth and everything that's in it., We toiled over what to engrave, and then finally I just said, Mike, just pick something that speaks to you, you're the craftsman, and so he selected that. There's certain ways to pull yourself in that book. Actually, Karl Deisseroth, he wrote the book Projections.\n",
      " One of my favorite, first of all, just as you said, incredible writer. Just, I mean, if you wrote fiction, if you wrote those kinds of things, I'm curious to see where he goes with his writing. It's very interesting. I think that book took him 10 years to write,\n",
      "```json\n",
      "{\n",
      "  \"entities\": [\n",
      "    {\n",
      "      \"name\": \"pitch and toss\",\n",
      "      \"definition\": \"A simple gambling game with coins\",\n",
      "      \"search_keyword\": \"pitch and toss + game\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Karl Deisseroth\",\n",
      "      \"definition\": \"Neuroscientist and author of 'Projections'\",\n",
      "      \"search_keyword\": \"Karl Deisseroth + person\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Projections\",\n",
      "      \"definition\": \"Book by neuroscientist Karl Deisseroth\",\n",
      "      \"search_keyword\": \"Projections Karl Deisseroth + book\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "```\n",
      "proactive_rare_word_agent_response entities=[Entity(name='pitch and toss', definition='A simple gambling game with coins', search_keyword='pitch and toss + game'), Entity(name='Karl Deisseroth', definition=\"Neuroscientist and author of 'Projections'\", search_keyword='Karl Deisseroth + person'), Entity(name='Projections', definition='Book by neuroscientist Karl Deisseroth', search_keyword='Projections Karl Deisseroth + book')]\n",
      "entities=[Entity(name='pitch and toss', definition='A simple gambling game with coins', search_keyword='pitch and toss + game'), Entity(name='Karl Deisseroth', definition=\"Neuroscientist and author of 'Projections'\", search_keyword='Karl Deisseroth + person'), Entity(name='Projections', definition='Book by neuroscientist Karl Deisseroth', search_keyword='Projections Karl Deisseroth + book')]\n",
      "{'url': 'https://en.wikipedia.org/wiki/Pitching_pennies', 'image_url': 'https://content.artofmanliness.com/uploads/2021/11/boys.jpg'}\n",
      "{'url': 'https://en.wikipedia.org/wiki/Karl_Deisseroth', 'image_url': 'https://upload.wikimedia.org/wikipedia/commons/thumb/6/68/Karl_Deisseroth_by_Christopher_Michel_04.jpg/800px-Karl_Deisseroth_by_Christopher_Michel_04.jpg'}\n",
      "{'url': 'https://www.amazon.com/Projections-Story-Emotions-Karl-Deisseroth/dp/1984853694', 'image_url': 'https://images.penguinrandomhouse.com/cover/9781984853714'}\n"
     ]
    }
   ],
   "source": [
    "test_transcript = generate_test_input()\n",
    "print(test_transcript)\n",
    "res = run_proactive_rare_word_agent_and_definer(test_transcript, [])\n",
    "print(res)\n",
    "for entities in res.entities:\n",
    "    res = await search_url_for_entity_async(entities.search_keyword)\n",
    "    if \"url\" not in res:\n",
    "        res = await search_url_for_entity_async(entities.search_keyword + \" wiki\")\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Just go for the best intuitive way that works the best\n",
    "\n",
    "Pipeline\n",
    "1. Check if page can be embed\n",
    "2. Check if url is accurate for definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if page can be embedded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The page can be embedded.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# URL of the page you want to check\n",
    "url = 'https://en.wikipedia.org/wiki/Borat_Sagdiyev'\n",
    "\n",
    "# Send a request to the URL\n",
    "response = requests.head(url)\n",
    "\n",
    "# Check the headers for 'X-Frame-Options' or 'Content-Security-Policy'\n",
    "x_frame_options = response.headers.get('X-Frame-Options')\n",
    "csp = response.headers.get('Content-Security-Policy')\n",
    "\n",
    "if x_frame_options or ('frame-ancestors' in csp if csp else False):\n",
    "    print(\"The page cannot be embedded.\")\n",
    "else:\n",
    "    print(\"The page can be embedded.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tosg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
